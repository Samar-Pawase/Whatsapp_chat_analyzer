{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samar-Pawase/Whatsapp_chat_analyzer/blob/main/GroupChatAnalyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCuNPj8ZYbih"
      },
      "outputs": [],
      "source": [
        "pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs5ESFeZ3OAb"
      },
      "outputs": [],
      "source": [
        "import regex\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZVp3wvI3SQV"
      },
      "outputs": [],
      "source": [
        "def date_time(s):\n",
        "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
        "    result = regex.match(pattern, s)\n",
        "    if result:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def find_author(s):\n",
        "    s = s.split(\":\")\n",
        "    if len(s)==2:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def getDatapoint(line):\n",
        "    splitline = line.split(' - ')\n",
        "    dateTime = splitline[0]\n",
        "    date, time = dateTime.split(\", \")\n",
        "    message = \" \".join(splitline[1:])\n",
        "    if find_author(message):\n",
        "        splitmessage = message.split(\": \")\n",
        "        author = splitmessage[0]\n",
        "        message = \" \".join(splitmessage[1:])\n",
        "    else:\n",
        "        author= None\n",
        "    return date, time, author, message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3O-Q3Hr3bKf"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdJT2V2s3WJH"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "conversation = 'WhatsApp Chat.txt'\n",
        "with open(conversation, encoding=\"utf-8\") as fp:\n",
        "    fp.readline()\n",
        "    messageBuffer = []\n",
        "    date, time, author = None, None, None\n",
        "    while True:\n",
        "        line = fp.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        line = line.strip()\n",
        "        if date_time(line):\n",
        "            if len(messageBuffer) > 0:\n",
        "                data.append([date, time, author, ' '.join(messageBuffer)])\n",
        "            messageBuffer.clear()\n",
        "            date, time, author, message = getDatapoint(line)\n",
        "            messageBuffer.append(message)\n",
        "        else:\n",
        "            messageBuffer.append(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-gwJUiM23sO6"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "print(df.head(20))\n",
        "print(df.info())\n",
        "print(df.Author.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXOGHUHD4FP4"
      },
      "outputs": [],
      "source": [
        "total_messages = df.shape[0]\n",
        "print(\"Total messages sent on Group\")\n",
        "print(total_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrfAeVeC4Rm2"
      },
      "outputs": [],
      "source": [
        "media_messages = df[df[\"Message\"]=='<Media omitted>'].shape[0]\n",
        "print(\"Total Media sent on Group\")\n",
        "print(media_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlV2RzPS4YqX"
      },
      "outputs": [],
      "source": [
        "def split_count(text):\n",
        "    emoji_list = []\n",
        "    data = regex.findall(r'\\X',text)\n",
        "    for word in data:\n",
        "        if any(char in emoji.UNICODE_EMOJI['en'] for char in word):\n",
        "            emoji_list.append(word)\n",
        "    return emoji_list\n",
        "df['emoji'] = df[\"Message\"].apply(split_count)\n",
        "\n",
        "emojis = sum(df['emoji'].str.len())\n",
        "print(\"Total emojis sent on Group\")\n",
        "print(emojis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoHQSYAo6MeU"
      },
      "outputs": [],
      "source": [
        "URLPATTERN = r'(https?://\\S+)'\n",
        "df['urlcount'] = df.Message.apply(lambda x: regex.findall(URLPATTERN, x)).str.len()\n",
        "links = np.sum(df.urlcount)\n",
        "\n",
        "print(\"Group chat\")\n",
        "print(\"Total Messages: \", total_messages)\n",
        "print(\"Number of Media Shared: \", media_messages)\n",
        "print(\"Number of Emojis Shared\", emojis)\n",
        "print(\"Number of Links Shared\", links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9KFgp698JEw"
      },
      "outputs": [],
      "source": [
        "media_messages_df = df[df['Message'] == '<Media omitted>']\n",
        "messages_df = df.drop(media_messages_df.index)\n",
        "messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\n",
        "messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\n",
        "messages_df[\"MessageCount\"]=1\n",
        "\n",
        "l = df.Author.unique()\n",
        "for i in range(len(l)):\n",
        "  req_df= messages_df[messages_df[\"Author\"] == l[i]]\n",
        "  print(\"***********************************************************\")\n",
        "  print(f'Stats of {l[i]} -')\n",
        "  print('1. Messages Sent', req_df.shape[0])\n",
        "  words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n",
        "  print('2. Average Words per message', words_per_message)\n",
        "  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n",
        "  print('3. Media Messages Sent', media)\n",
        "  emojis = sum(req_df['emoji'].str.len())\n",
        "  print('4. Emojis Sent', emojis)\n",
        "  links = sum(req_df[\"urlcount\"])   \n",
        "  print('5. Links Sent', links)\n",
        "  print(\"***********************************************************\")\n",
        "  print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-btAe_bJLqMq"
      },
      "outputs": [],
      "source": [
        "total_emojis_list = []\n",
        "total_emojis = len(total_emojis_list)\n",
        "\n",
        "total_emojis_list = list([a for b in messages_df.emoji for a in b])\n",
        "emoji_dict = dict(Counter(total_emojis_list))\n",
        "emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n",
        "import plotly.express as px\n",
        "fig = px.pie(emoji_df, values='count', names='emoji')\n",
        "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzKFjozyO9Tk"
      },
      "outputs": [],
      "source": [
        "text = \" \".join(review for review in messages_df.Message)\n",
        "print (\"There are {} words in all the messages.\".format(len(text)))\n",
        "stopwords = frozenset(STOPWORDS)\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "plt.figure( figsize=(10,5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymFdH_BMUWxz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1cGUXhjR5bg"
      },
      "outputs": [],
      "source": [
        "\n",
        "l = df.Author.unique()\n",
        "for i in range(len(l)):\n",
        "  dummy_df = messages_df[messages_df['Author'] == l[i]]\n",
        "  text = \" \".join(review for review in dummy_df.Message)\n",
        "  stopwords = frozenset(STOPWORDS)\n",
        "  print(l[i])\n",
        "  print(\"Total words used - \",len(text))\n",
        "  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "  plt.figure( figsize=(10,5))\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "GroupChatAnalyzer.ipynb",
      "provenance": [],
      "mount_file_id": "15nRMAPdh5lOu-zPZK2w_7mM8NlzECKRp",
      "authorship_tag": "ABX9TyOt9dIb3bt8n7pjWDcqtQyh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}